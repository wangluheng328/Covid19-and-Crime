data_ingest:
  data_ingest.txt explains how the data is manually downloaded from its original website
  and then uploaded to hdfs 
etl_code:
  wes:
    initial cleaning code by wesley wang using mapreduce
    Clean.java, CleanMapper.java, CleanReducer.java are the cleaning code
  kyle:
    initial cleaning code by kyle ma using mapreduce
    Clean.java, CleanMapper.java, CleanReducer.java are the cleaning code
profiling_code:
  wes:
    initial profiling code by wesley wang using mapreduce
    CountRecs.java, CountRecsMapper.java, CountRecsReducer.java are the profiling code
  kyle:
    initial profiling code by kyle ma using mapreduce
    CountRecs.java, CountRecsMapper.java, CountRecsReducer.java are the profiling code
ana_code:
  additional_process
    additional_process.SCALA
    the code unifies the date column format for both crime_new.csv and epid_new.csv that generated
    from the initial cleaning process
    so the date from two data set matches in terms of range and type
    it also drops columns irrelevant to future analysis
    it then output three csv files for future analysis
      crime_date.csv: data from crime_new.csv grouped by date and count total incident per date
      crime_type.csv: data from crime_new.csv grouped by date and type then count total incident per date for each type
      epid_clean.csv: data from epid_new.csv without unnecessary columns and uniformed date format
    a few demonstrations would be shown on the interface in the process
  basic_statistics: ToDo
    allcrime_day_stats.SCALA:
    allcrime_newconfirmed_month_stats.SCALA:
    allcrime_newdeceased_month_stats.SCALA:
  correlation_analysis:
    allcrime_newcomfirmed_day_corr.SCALA:
    allcrime_newcomfirmed_month_corr.SCALA:
    allcrime_newdeceased_day_corr.SCALA:
    allcrime_newdeceased_month_corr.SCALA:
    typecrime_newconfirmed_day_corr.SCALA:
      the code finds correlation between daily newconfirmed covide cases and the number of four types of crime incidents
      the four incidents are Robbery, Felony assult, Sex crimes, and Harrassment 2.
      the result is printed:
        //Robbery Correlation is: -0.37035180358283887
	//FELONY ASSAULT Correlation is: -0.46913761145316174
	//SEX CRIMES Correlation is: -0.45638676093112335
	//HARRASSMENT 2 Correlation is: -0.6489481870609697
  additional_analysis
    crime_month_before_after.SCALA:
      check which month do crime happen most frequently before and after covid
      by isolating the data from 2019 and 2020 from crime_new.csv and transform the datetype of date column to month
      the crime count from 2019 and 2020 per month are generated by group the data set by month and count
      result shows that:
        //in 2019 before covid July is when crime happen most frequently
        //in 2020 after covid August is when crime happen most frequently
      for exploration purpose
      the crime count from 2019 and 2020 are also grouped by month and type 
      the result is output into csv files for easier examination
    crime_weekday_before_after.SCALA:
      check which weekday do crime happen most frequently before and after covid
      by isolating the data from 2019 and 2020 from crime_new.csv and transform the datetype of date column to weekday
      the crime count from 2019 and 2020 per month are generated by group the data set by weekday and count
      the one weekday with 53 occurence is normalized by multipling 52/53 
      result shows that:
	//in 2019 before covid Friday is when crime happen most frequently
	//in 2020 after covid Friday is when crime happen most frequently
	//There is not much difference except for all days in a week, crime happen less after covid

***All csv can be found on project_data folder in hm1920's hdfs

How to run my code:
1. follow the instruction in data_ingest/data_ingest.txt
   download the data sets and put them to hdfs
   result can be found in project_data/crime.csv and project_data/epid.csv
   due to storage issue data folder is not included in the assignment submission
   they can be found on the hdfs
2. run the mapreduce job Clean.java in etl_code/wes following the normal procedure
   of running mapreduce jobs on nyu cluster
   the input is: crime.csv
   the output is cleaned data: crime_new.csv
3. run the mapreduce job Clean.java in etl_code/kyle following the normal procedure
   of running mapreduce jobs on nyu cluster
   the input is: epid.csv
   the output is cleaned data: epid_new.csv
4. run the mapreduce job CountRecs.java in profiling_code/wes following the normal procedure
   of running mapreduce jobs on nyu cluster
   the input is: crime_new.csv
   the output is row count of the input data
   this gives a better idea of the output csv files from Clean.java
5. run the mapreduce job CountRecs.java in profiling_code/kyle following the normal procedure
   of running mapreduce jobs on nyu cluster
   the input is: epid_new.csv
   the output is row count of the input data
   this gives a better idea of the output csv files from Clean.java
6. Additional_Process
   put the additional_process.scala from ana_code/additional_process folder to hdfs
   make sure that both epid_new.csv and crime_new.csv are also put on the cluster
   run by open spark and type command :load additional_process.scala
   a few desmonstration will show on the command prompt and three output csv will be created
7. Basic statistics
8. Additional Analysis
    crime_month_before_after
      put crime_month_before_after.scala from ana_code/additional_analysis folder to hdfs
      makesure that crime_new.csv is also on hdfs
      run by open spark and type command :load crime_month_before_after.scala 
      the crime count from 2019 and 2020 grouped by month will be printed on the screen
      the crime count from 2019 and 2020 grouped by month and type will be output as csv
        month_type_2019.csv and month_type_2020.csv
    crime_weekday_before_after
      put crime_weekday_before_after.scala from ana_code/additional_analysis folder to hdfs
      makesure that crime_new.csv is also on hdfs
      run by open spark and type command :load crime_weekday_before_after.scala 
      the crime count from 2019 and 2020 grouped by weekday will be printed on the screen
      

9. Correlation Analysis
    typecrime_newconfirmed_day_corr
      put typecrime_newconfirmed_day_corr.scala from ana_code/correlation_analysis folder to hdfs
      makesure that crime_type.csv and epid_clean.csv are also on hdfs
      run by open spark and type command :load typecrime_newconfirmed_day_corr.scala
      the correlation between four types of crime counts and daily counts of newly confirmed covid cases 
      will be print on the screen